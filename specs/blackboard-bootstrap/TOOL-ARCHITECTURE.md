# Spec: Tool Architecture (File-Based Discovery)

**Date**: 2026-02-17
**Status**: Draft
**Bead**: cursor-onboarding-kit-[TBD]

---

## Problem

MCP servers require a running process. For a "blackboard" cognitive architecture, we want:
- Zero runtime dependencies for core functionality
- Cursor IDE compatibility (no hook API, but file-based tool discovery)
- Sub-millisecond tool discovery
- Agent-native: tools as files, not API calls

---

## Solution: Tools as Files (Cursor Pattern)

From [Cursor Dynamic Context Discovery](https://cursor.com/blog/dynamic-context-discovery):

> We create one folder per server, keeping each server's tools logically grouped. When the model lists a folder, it sees all tools from that server together and can understand them as a cohesive unit. Files also enable more powerful searching. The agent can use full `rg` parameters or even `jq` to filter tool descriptions.

**Result**: 46.9% token reduction when MCP tools are file-based vs always-loaded.

---

## Architecture

```
~/workshop/
â”œâ”€â”€ bench/                    # Graph space (MOCs, identity)
â”‚   â”œâ”€â”€ index.md             # Hub MOC
â”‚   â”œâ”€â”€ identity.md          # Who am I, what do I know
â”‚   â””â”€â”€ methodology.md       # How I work
â”‚
â”œâ”€â”€ shavings/                 # Notes (atomic insights)
â”‚   â””â”€â”€ *.md                 # Individual shavings
â”‚
â”œâ”€â”€ sawdust/                  # Ops (sessions, queues)
â”‚   â”œâ”€â”€ sessions/            # Session logs
â”‚   â””â”€â”€ queue/               # Processing queue
â”‚
â””â”€â”€ .workshop/               # Workshop configuration
    â”œâ”€â”€ tools/               # Tool definitions (files!)
    â”‚   â”œâ”€â”€ core/
    â”‚   â”‚   â”œâ”€â”€ cut.md       # Extract insight from source
    â”‚   â”‚   â”œâ”€â”€ carve.md     # Find connections
    â”‚   â”‚   â”œâ”€â”€ chamfer.md   # Update older shavings
    â”‚   â”‚   â”œâ”€â”€ check.md     # Validation + health
    â”‚   â”‚   â””â”€â”€ sharpen.md   # Meta-cognitive refinement
    â”‚   â”œâ”€â”€ search/
    â”‚   â”‚   â”œâ”€â”€ rg.md        # Ripgrep search
    â”‚   â”‚   â”œâ”€â”€ semantic.md  # Vector search (optional)
    â”‚   â”‚   â””â”€â”€ graph.md     # Graph traversal
    â”‚   â””â”€â”€ setup/
    â”‚       â”œâ”€â”€ init.md      # Bootstrap new workshop
    â”‚       â”œâ”€â”€ calibrate.md # Adjust configuration
    â”‚       â””â”€â”€ health.md    # Diagnostic checks
    â”‚
    â”œâ”€â”€ schema.yaml          # Caliper validation rules
    â”œâ”€â”€ config.yaml          # Workshop configuration
    â””â”€â”€ policy.univ          # Optional: taint policy (Universalis-style)
```

---

## Tool Definition Format

Each tool is a markdown file with YAML frontmatter:

```markdown
---
name: cut
description: Extract atomic insight from source with code context
category: core
requires:
  - ripgrep
performance:
  target: 1ms
  warning: 10ms
  panic: 50ms
invocation: workshop cut <source> [--with-code-ref]
---

# Cut

Extract an atomic insight (shaving) from a source file.

## Usage

```bash
workshop cut src/auth/login.ts --with-code-ref
```

## What it does

1. Reads the source file
2. Identifies key concepts/patterns
3. Creates a new shaving in `shavings/`
4. Optionally embeds `file:line` reference

## Output

Creates: `shavings/<prose-title>.md`

## Schema

```yaml
title: <prose proposition>
description: <mechanism or implication>
source: <file:line or URL>
created: <ISO date>
topics: [<topic>, ...]
```
```

---

## Tool Discovery Protocol

### For Cursor Agent

1. Agent lists `.workshop/tools/` to see available tools
2. Agent uses `rg` to search tool descriptions:
   ```bash
   rg -t md "extract" .workshop/tools/
   ```
3. Agent reads specific tool file for full instructions
4. Agent invokes tool via shell or CLI

### For Claude Code

Same protocol, but can also use MCP wrapper for structured I/O.

---

## Performance Budgets

From `destructive_command_guard` pattern:

| Tier | Target | Warning | Panic |
|------|--------|---------|-------|
| Quick reject | < 1Î¼s | > 10Î¼s | > 50Î¼s |
| Fast path | < 75Î¼s | > 200Î¼s | > 500Î¼s |
| Full pipeline | < 5ms | > 10ms | > 20ms |

Applied to workshop tools:

| Tool | Budget | Strategy |
|------|--------|----------|
| `cut` | 1ms | memchr quick reject, lazy file read |
| `carve` | 75ms | ripgrep + parallel processing |
| `chamfer` | 5ms | targeted updates only |
| `check` | 10ms | cached validation |
| `search` | 1ms | xf-style hybrid (Tantivy + vectors) |

---

## Rust CLI Structure

From `xf` and `destructive_command_guard` patterns:

```rust
// src/main.rs
fn main() -> Result<()> {
    let cli = Cli::parse();

    // Robot mode for machine-readable output
    let robot = cli.robot;

    match cli.command {
        Commands::Cut { source, with_code_ref } => {
            let budget = PerformanceBudget::fast_path();
            cmd::cut(source, with_code_ref, budget, robot)?
        }
        Commands::Carve { query } => {
            let budget = PerformanceBudget::full_pipeline();
            cmd::carve(query, budget, robot)?
        }
        // ...
    }
    Ok(())
}
```

### Key Dependencies

```toml
[dependencies]
clap = { version = "4", features = ["derive"] }
anyhow = "1"
serde = { version = "1", features = ["derive"] }
serde_yaml = "0.9"
memchr = "2"           # SIMD-accelerated search
ripgrep = "14"         # Or use grep-matcher crate
tantivy = "0.21"       # Full-text search (optional)
rayon = "1"            # Parallel processing
```

---

## Setup Script (Gum-Based)

From user requirement: professional, emoji-driven, energetic.

```bash
#!/usr/bin/env bash
# setup.sh - Bootstrap your Workshop

set -e

# Colors and emojis
GUM_SPIN_STYLE="gum style --foreground 212 --bold"
EMOJI_WORKSHOP="ðŸªµ"
EMOJI_BENCH="ðŸª‘"
EMOJI_SHAVING="ðŸªš"
EMOJI_SAWDUST="ðŸ’¨"

echo ""
$GUM_SPIN_STYLE "$EMOJI_WORKHOUSE Welcome to the Workshop!"
echo ""

# Phase 1: Detect
gum spin --spinner dot --title "Detecting environment..." -- sleep 0.5
echo "  âœ“ Found: $(uname -s)"
echo "  âœ“ Gum: $(gum --version | head -1)"
echo ""

# Phase 2: Understand
$GUM_SPIN_STYLE "$EMOJI_BENCH Let's hang your blackboard..."
echo ""

WORK_TYPE=$(gum choose --header "What kind of work do you do?" \
    "software" "research" "writing" "other")

CODE_REFS=$(gum choose --header "Should shavings reference code?" \
    "yes" "no" "optional")

LOCATION=$(gum input --header "Where should we put the workshop?" \
    --value "./workshop")

# Phase 3: Derive (internal)
gum spin --spinner dot --title "Deriving configuration..." -- sleep 1

# Phase 4: Proposal
echo ""
$GUM_SPIN_STYLE "$EMOJI_SHAVING Here's what I'll create:"
echo ""
echo "  $LOCATION/"
echo "  â”œâ”€â”€ bench/      (your workbench)"
echo "  â”œâ”€â”€ shavings/   (curled insights)"
echo "  â”œâ”€â”€ sawdust/    (ephemeral byproduct)"
echo "  â””â”€â”€ .workshop/  (configuration)"
echo ""

CONFIRM=$(gum confirm "Looks good?" && echo "yes" || echo "no")

if [ "$CONFIRM" != "yes" ]; then
    echo "Cancelled. Run again when ready."
    exit 0
fi

# Phase 5: Generate
gum spin --spinner dot --title "$EMOJI_SAWDUST Generating workshop..." -- {
    mkdir -p "$LOCATION"/{bench,shavings,sawdust,.workshop/tools/{core,search,setup}}

    # Generate identity
    cat > "$LOCATION/bench/identity.md" << EOF
---
created: $(date -Iseconds)
work_type: $WORK_TYPE
code_refs: $CODE_REFS
---

# Workshop Identity

This is your workshop. The bench is your workspace, shavings are your insights,
and sawdust is the ephemeral byproduct of thinking.

Configure me during setup or edit directly.
EOF

    # Generate tool definitions
    cp -r ~/.workshop/templates/tools/* "$LOCATION/.workshop/tools/"
}

# Phase 6: Validate
echo ""
$GUM_SPIN_STYLE "âœ¨ Workshop ready!"
echo ""
echo "  Next steps:"
echo "    cd $LOCATION"
echo "    workshop health"
echo ""
```

---

## Taint Policy (Optional, Universalis-Style)

For security-conscious workflows, define a taint policy:

```yaml
# .workshop/policy.univ
# Security policy for workshop operations

sources:
  - pred: "read_file"
    field: "contents"
    reason: "Files may contain sensitive data"

sinks:
  - pred: "curl_post"
    data_field: "data"
    dest_field: "url"
    reason: "Network calls can exfiltrate data"

safe_destinations:
  - "internal.company.com"
  - "cdn.trusted.com"

rules:
  - name: "no_exfiltration"
    description: "Tainted data cannot reach untrusted destinations"
    violation: "source â†’ sink â†’ !safe"
```

This would be validated by a separate `workshop verify` command that runs taint analysis before executing workflows.

---

## Integration with Cursor

Since Cursor has no hook API, integration is file-based:

1. **Tool Discovery**: Cursor agent reads `.workshop/tools/**/*.md`
2. **Session Capture**: Write to `sawdust/sessions/` (file watcher optional)
3. **Context Injection**: Cursor can read `bench/identity.md` for context
4. **Terminal Sync**: Cursor syncs terminal output to files (already does this)

No MCP server needed for core functionality.

---

## Open Questions

1. Should tools be versioned with the workshop, or shared globally?
2. How do we handle tool updates without breaking existing workshops?
3. Should there be a tool registry/marketplace?
4. How does this interact with Claude Code's skill system?

---

## References

- [Cursor Dynamic Context Discovery](https://cursor.com/blog/dynamic-context-discovery)
- [destructive_command_guard](https://github.com/Dicklesworthstone/destructive_command_guard)
- [xf](https://github.com/Dicklesworthstone/xf)
- [coding_agent_session_search](https://github.com/Dicklesworthstone/coding_agent_session_search)
- Universalis: "In Code They Think; In Proof We Trust" (Google Doc)
- arscontexta: 249 research claims, 6-phase setup
